# Aims to replicate results reported in
# "Minimal Intelligence Agents for Bargaining Behaviours in
# Market-based Environments" Dave Cliff 1997
#
# To run this experiment use the command:
#
#  java uk.ac.liv.auction.MarketSimulation examples/zip-kcda-randomschedule.params
#

simulation.iterations = 50

simulation.auction = uk.ac.liv.auction.core.RandomRobinAuction
simulation.auction.name = PvT in kCDA with Random Schedule

simulation.auction.closing = uk.ac.liv.auction.core.MaxDaysAuctionClosingCondition
simulation.auction.closing.maximumdays = 5
simulation.auction.dayending = uk.ac.liv.auction.core.MaxRoundsDayEndingCondition
simulation.auction.dayending.lengthofday = 50


# Show GUI console
simulation.auction.console = false

simulation.auction.auctioneer = uk.ac.liv.auction.core.ContinuousDoubleAuctioneer
simulation.auction.auctioneer.pricing = uk.ac.liv.auction.core.DiscriminatoryPricingPolicy
simulation.auction.auctioneer.pricing.k = 0.5


# Configure a combination of two different reports
simulation.auction.report = uk.ac.liv.auction.stats.CombiAuctionReport

simulation.auction.report.n = 3

simulation.auction.report.0 = uk.ac.liv.auction.stats.DailyStatsReport
simulation.auction.report.1 = uk.ac.liv.auction.stats.SurplusReport
simulation.auction.report.2 = uk.ac.liv.auction.stats.HistoricalDataReport

# Two populations of agents
simulation.auction.agenttype.n = 2

# 1st population
simulation.auction.agenttype.0 = uk.ac.liv.auction.zi.ZITraderAgent
simulation.auction.agenttype.0.numagents = 11
simulation.auction.agenttype.0.initialtradeentitlement = 10
simulation.auction.agenttype.0.strategy = uk.ac.liv.auction.agent.PriestVanTolStrategy
simulation.auction.agenttype.0.strategy.scaling = 0.05
simulation.auction.agenttype.0.strategy.learner = uk.ac.liv.ai.learning.WidrowHoffLearnerWithMomentum
simulation.auction.agenttype.0.strategy.learner.learningrate = 0.3
simulation.auction.agenttype.0.strategy.learner.momentum = 0.05
simulation.auction.agenttype.0.isseller = true
simulation.auction.agenttype.0.valuer = uk.ac.liv.auction.agent.DistinctDistributionValuer
simulation.auction.agenttype.0.valuer.minvaluemin = 161
simulation.auction.agenttype.0.valuer.minvaluemax = 260
simulation.auction.agenttype.0.valuer.rangemin = 90
simulation.auction.agenttype.0.valuer.rangemax = 100

# 2nd population
simulation.auction.agenttype.1 = uk.ac.liv.auction.zi.ZITraderAgent
simulation.auction.agenttype.1.numagents = 11
simulation.auction.agenttype.1.initialtradeentitlement = 10
simulation.auction.agenttype.1.strategy = uk.ac.liv.auction.agent.PriestVanTolStrategy
simulation.auction.agenttype.1.strategy.scaling = 0.05
simulation.auction.agenttype.1.strategy.learner = uk.ac.liv.ai.learning.WidrowHoffLearnerWithMomentum
simulation.auction.agenttype.1.strategy.learner.learningrate = 0.3
simulation.auction.agenttype.1.strategy.learner.momentum = 0.05
simulation.auction.agenttype.1.isseller = false
simulation.auction.agenttype.1.valuer = uk.ac.liv.auction.agent.DistinctDistributionValuer
simulation.auction.agenttype.1.valuer.minvaluemin = 161
simulation.auction.agenttype.1.valuer.minvaluemax = 260
simulation.auction.agenttype.1.valuer.rangemin = 90
simulation.auction.agenttype.1.valuer.rangemax = 100


# PRNG configuration
#  Use the 32bit version of the Mersenne Twister algorithm 
simulation.prng = uk.ac.liv.prng.MT32
#  with the following PRNG seed
simulation.seed = 4523

# log4j configuration - substitute DEBUG instead of INFO to turn on debugging 
log4j.rootCategory=INFO, stdout
log4j.appender.stdout=org.apache.log4j.ConsoleAppender
log4j.appender.stdout.layout=org.apache.log4j.PatternLayout
log4j.appender.stdout.layout.ConversionPattern=%m%n
