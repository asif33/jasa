#
# This example demonstrates a non-interactive batch experiment 
# involving ten iterations of a discriminatory-price k-DA 
# electricity market.
#
# To quickly run this example, use the following shell command:
#
#  ant batchrun -Dparams=examples/example1.params
#
# Alternatively, for performance, set your CLASSPATH environment variable
# to include all of the JASA libraries, and then run the command:
#
#  java -server uk.ac.liv.auction.MarketSimulation examples/example1.params
#

# Perform ten iterations of the experiment
simulation.iterations = 10

# Write the results of each iteration to the following 
#  comma-separated-variables (CSV) file
simulation.writer = uk.ac.liv.util.io.CSVWriter
simulation.writer.filename = results.csv

# Use a random-robin auction which will randomise the order in which agents bid
simulation.auction = uk.ac.liv.auction.core.RandomRobinAuction
simulation.auction.name = Example 1: discriminatory-price electricity k-DA

# The auction will close after 100 rounds (or "ticks")
simulation.auction.maximumrounds = 100

# Use a k-DA auctioneer- clearing will occur at the end of each
#  round after every agent has had a chance to place a shout
simulation.auction.auctioneer = uk.ac.liv.auction.core.KDoubleAuctioneer

# Set the transaction price as a function of individual bid and ask prices
simulation.auction.auctioneer.pricing = uk.ac.liv.auction.core.DiscriminatoryPricingPolicy

# Set the transaction price halfway between the bid and the ask price
simulation.auction.auctioneer.pricing.k = 0.5

# Configure a combination of three different reports
simulation.auction.report = uk.ac.liv.auction.stats.CombiAuctionReport
simulation.auction.report.n = 3

# The first report collects stats on the auction as it progresses
simulation.auction.report.0 = uk.ac.liv.auction.stats.PriceStatisticsReport

# The second report collects data on profit distribution
simulation.auction.report.1 = uk.ac.liv.auction.stats.SurplusReport

# In addition, generate a report on the relative concentration 
#  and capacity of the electricity traders
simulation.auction.report.2 = uk.ac.liv.auction.electricity.ElectricityStats

# Do not show the GUI console, as this is a batch experiment
simulation.auction.console = false

# Two populations of agents
simulation.auction.agenttype.n = 2

# 1st population-
#  100 electricity sellers with a capacity of 10MWh
#  using the Roth-Erev strategy
simulation.auction.agenttype.0 = uk.ac.liv.auction.electricity.ElectricityTrader
simulation.auction.agenttype.0.numagents = 100
simulation.auction.agenttype.0.isseller = true
# Valuations will be drawn randomly at the start of the auction
simulation.auction.agenttype.0.valuer = uk.ac.liv.auction.agent.RandomValuer
# Valuations will be distributed uniformly in the range (10, 100)
simulation.auction.agenttype.0.valuer.minvalue = 10
simulation.auction.agenttype.0.valuer.maxvalue = 100
# Generating capacity is 10MWh
simulation.auction.agenttype.0.capacity = 10
# Use a myopic stimuli-response algorithm
simulation.auction.agenttype.0.strategy = uk.ac.liv.auction.agent.StimuliResponseStrategy
# Multiply the discrete output from the learning algorithm by $1
simulation.auction.agenttype.0.strategy.markupscale = 1
# Use NPT modifications to the Roth-Erev learning algorithm
simulation.auction.agenttype.0.strategy.learner = uk.ac.liv.ai.learning.NPTRothErevLearner
# ..configured with 100 different actions, ie markups
simulation.auction.agenttype.0.strategy.learner.k = 100

# 2nd population-
#  100 electricity buyers
#  using the modified Roth-Erev strategy
simulation.auction.agenttype.1 = uk.ac.liv.auction.electricity.ElectricityTrader
simulation.auction.agenttype.1.numagents = 100
simulation.auction.agenttype.1.isseller = false
# Valuations will be drawn randomly for each unit that we trade
simulation.auction.agenttype.1.valuer = uk.ac.liv.auction.agent.RandomValuer
# Valuations will be in the range (80, 150)
simulation.auction.agenttype.1.valuer.minvalue = 80
simulation.auction.agenttype.1.valuer.maxvalue = 150
# Generating capacity is 10MWh
simulation.auction.agenttype.1.capacity = 10
# Use a myopic stimuli-response algorithm
simulation.auction.agenttype.1.strategy = uk.ac.liv.auction.agent.StimuliResponseStrategy
# Multiply the discrete output from the learning algorithm by $1
simulation.auction.agenttype.1.strategy.markupscale = 1
# Use NPT modifications to the Roth-Erev learning algorithm
simulation.auction.agenttype.1.strategy.learner = uk.ac.liv.ai.learning.NPTRothErevLearner
# ..with 100 different markups to choose from
simulation.auction.agenttype.1.strategy.learner.k = 100

# PRNG configuration
#  use the 32bit version of the Mersenne Twister algorithm
simulation.prng = uk.ac.liv.prng.MT32
#  with the following PRNG seed
simulation.seed = 1298

# log4j configuration - substitute DEBUG instead of INFO to turn on debugging
log4j.rootCategory=INFO, stdout
log4j.appender.stdout=org.apache.log4j.ConsoleAppender
log4j.appender.stdout.layout=org.apache.log4j.PatternLayout
log4j.appender.stdout.layout.ConversionPattern=%m%n
